{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adjusted-carry",
   "metadata": {},
   "source": [
    "# Simulating Circuits for DM4 and DL5\n",
    "\n",
    "This notebook provides cells that run different circuits; the results of the simulations can be explored with the CircuitVisualization notebook.\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from neurokernel.LPU.InputProcessors.StepInputProcessor import StepInputProcessor\n",
    "import numpy as np\n",
    "name = 'DM4_step1_'\n",
    "main_path = '/mnt/server-home/mehmet/alclustering/'\n",
    "G_path = main_path + '{}.gexf'.format(name)\n",
    "visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "def large_scale_sim(name, G_path, conc = 1., DM4_b = 2.17 * 1e-2, DM4_d = 2.94, DL5_b = 0.1 * 2.94, exp_name = '', LN_3=False, LN_3_I = 10.):\n",
    "    # Simulation function specifically to run DM4 and DL5 graphs. \n",
    "    G = nx.read_gexf(G_path)\n",
    "    G = nx.MultiDiGraph(G)\n",
    "    sim_name = name + '_conc_' + str(conc) + exp_name\n",
    "    def set_br(G):\n",
    "        for node in G.nodes():\n",
    "            if '_OTP' in node:\n",
    "                if 'DC1' in node:\n",
    "                    G.nodes(data=True)[node]['br'] = 0.\n",
    "                elif 'DM4' in node:\n",
    "                    G.nodes(data=True)[node]['br'] = DM4_b\n",
    "                    G.nodes(data=True)[node]['dr'] = DM4_d\n",
    "                    # print('found DM4')\n",
    "                else:\n",
    "                    # G.nodes(data=True)[node]['br'] = 0.01\n",
    "                    G.nodes(data=True)[node]['br'] = DL5_b\n",
    "                    G.nodes(data=True)[node]['dr'] = DM4_d\n",
    "        return G\n",
    "\n",
    "    G = set_br(G)\n",
    "    inputs = [i for i in G.nodes() if '_OTP' in i]\n",
    "    fi = StepInputProcessor('conc', inputs, conc, start=1., stop=3.)\n",
    "    print('Concentration Level:', conc)\n",
    "    print('Inputs:', inputs)\n",
    "    def simulate(G, t, inputs,\n",
    "        record_var_list = None,\n",
    "        sample_interval: int = 100,\n",
    "    ):\n",
    "        from neurokernel.LPU.LPU import LPU\n",
    "        from neurokernel.LPU.InputProcessors.BaseInputProcessor import (\n",
    "            BaseInputProcessor,\n",
    "        )\n",
    "        from neurokernel.LPU.InputProcessors.ArrayInputProcessor import (\n",
    "            ArrayInputProcessor,\n",
    "        )\n",
    "        from neurokernel.LPU.OutputProcessors.OutputRecorder import OutputRecorder\n",
    "        from neurokernel.LPU.OutputProcessors.FileOutputProcessor import FileOutputProcessor\n",
    "\n",
    "        dt = t[1] - t[0]\n",
    "        if isinstance(inputs, BaseInputProcessor):\n",
    "            fi = [inputs]\n",
    "        elif isinstance(inputs, (list, tuple, np.ndarray)) and isinstance(\n",
    "            inputs[0], BaseInputProcessor\n",
    "        ):\n",
    "            fi = inputs\n",
    "        elif isinstance(inputs, dict):\n",
    "            for data in inputs.values():\n",
    "                assert \"uids\" in data\n",
    "                assert \"data\" in data\n",
    "                assert isinstance(data[\"data\"], np.ndarray)\n",
    "            fi = [ArrayInputProcessor(inputs)]\n",
    "        else:\n",
    "            raise ValueError(\"Input not understood\")\n",
    "            \n",
    "        if LN_3:\n",
    "            fi += [StepInputProcessor('I', ['LN_3'], LN_3_I, start=1., stop=3.)]\n",
    "            print('Adding current to LN3.')\n",
    "\n",
    "        fo = OutputRecorder([('I', None), ('g', None)], sample_interval=sample_interval)\n",
    "        fo2 = OutputRecorder([('spike_state', None)], sample_interval=1)\n",
    "        fo3 = OutputRecorder([('V', None)], sample_interval=1)\n",
    "        lpu = LPU(\n",
    "            dt,\n",
    "            \"obj\",\n",
    "            G,\n",
    "            device=0,\n",
    "            id=\"EOS\",\n",
    "            input_processors=fi,\n",
    "            output_processors=[fo, fo2, fo3],\n",
    "            debug=False,\n",
    "            manager=False\n",
    "        )\n",
    "        lpu.run(steps=len(t))\n",
    "\n",
    "        fo.to_file('sim_results2/fo_{}'.format(sim_name))\n",
    "        fo2.to_file('sim_results2/fo2_{}'.format(sim_name))\n",
    "        fo3.to_file('sim_results2/fo3_{}'.format(sim_name))\n",
    "        return fi, fo, fo2, fo3, lpu\n",
    "    return simulate, G, fi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-immune",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "class PSTH(object):\n",
    "    \"\"\"Peri-Stimulus Time Histogram\n",
    "    This class facilitates computing PSTH of input spikes in an OOP fashion.\n",
    "    For 2D spiking data, the PSTH is computed as an average across spike times\n",
    "    for all neurons.\n",
    "    .. seealso:: :py:func:`compute_psth`\n",
    "    Parameters:\n",
    "        spikes: 1D or 2D binary array of spike trains to compute PSTH from. For\n",
    "            2D array, the temporal axis is infered as the longer dimension. The\n",
    "            other dimension is treated as neuron indices.\n",
    "        dt: time-step for spikes along the temporal dimension of :code:`spikes`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, spikes: np.ndarray, dt: float, window: float = 20e-3, shift: float = 10e-3\n",
    "    ):\n",
    "        self.window = window\n",
    "        self.shift = shift\n",
    "        self.dt = dt\n",
    "        self.spikes = spikes\n",
    "        self.psth, self.t = self.compute()\n",
    "\n",
    "    def compute(self):\n",
    "        spikes = self.spikes\n",
    "        if len(spikes.shape) > 1:\n",
    "            axis = int(spikes.shape[0] > spikes.shape[1])\n",
    "            spikes = np.mean(spikes, axis=axis)\n",
    "\n",
    "        cum_spikes = np.cumsum(spikes)\n",
    "\n",
    "        duration = self.dt * len(cum_spikes)\n",
    "        start = np.arange(0.0, duration - self.window, self.shift) // self.dt\n",
    "        stop = np.arange(self.window, duration - self.dt, self.shift) // self.dt\n",
    "        start = start.astype(int, copy=False)\n",
    "        stop = stop.astype(int, copy=False)\n",
    "\n",
    "        start = start[: len(stop)]\n",
    "\n",
    "        rates = (cum_spikes[stop] - cum_spikes[start]) / self.window\n",
    "        stamps = np.arange(0, len(rates) * self.shift - self.dt, self.shift)\n",
    "\n",
    "        return rates, stamps\n",
    "\n",
    "    def merge(self, others):\n",
    "        if not hasattr(others, \"__len__\"):\n",
    "            others = [others]\n",
    "        for other in others:\n",
    "            assert np.all(self.t == other.t)\n",
    "\n",
    "        stack = [self.psth]\n",
    "        for other in others:\n",
    "            stack.append(other.psth)\n",
    "\n",
    "        self.psth = np.vstack(stack)\n",
    "\n",
    "def gen_step2_plots(fo, fo2, fo3, sim_name, filter_keyword = 'DM4', PN_filter_keyword = 'DM4'):\n",
    "    tk = 1650\n",
    "    plot_data = []\n",
    "    back_plot_data = []\n",
    "    interesting_components = []\n",
    "    interesting_data = []\n",
    "    sim_traces = {}\n",
    "    \n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    fig.patch.set_facecolor('xkcd:black')\n",
    "\n",
    "    f = plt.subplot(7,1,1)\n",
    "    f.patch.set_facecolor('xkcd:black')\n",
    "    data = fo3.get_output(var='V')\n",
    "    PNs = [i for i in data.keys() if 'ORN' in i and filter_keyword in i]\n",
    "    sim_traces['V_ORN'] = {}\n",
    "    for PN in PNs[:]:\n",
    "        plt.plot(data[PN]['time'], data[PN]['data'])\n",
    "        sim_traces['V_ORN'][PN] = {'time': data[PN]['time'], 'data': data[PN]['data']}\n",
    "    try:\n",
    "        time_axis = data[PN]['time'].copy()\n",
    "    except:\n",
    "        return sim_traces\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Membrane Potential')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['top'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['right'].set_color('white')\n",
    "    ax.xaxis.label.set_color('white')\n",
    "    ax.yaxis.label.set_color('white')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    ax.set_title('ORN Activity For {} ppm Acetone Delivery'.format(int(conc)), color='white')\n",
    "    #ax.axvline(x=[time], color='white')\n",
    "\n",
    "\n",
    "    f = plt.subplot(7,1,2)\n",
    "    f.patch.set_facecolor('xkcd:black')\n",
    "    data = fo3.get_output(var='V')\n",
    "    PNs = [i for i in data.keys() if 'PN' in i and PN_filter_keyword in i]\n",
    "    sim_traces['V_PN'] = {}\n",
    "    for PN in PNs[:]:\n",
    "        plt.plot(data[PN]['time'], data[PN]['data'])\n",
    "        sim_traces['V_PN'][PN] = {'time': data[PN]['time'], 'data': data[PN]['data']}\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Membrane Potential')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['top'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['right'].set_color('white')\n",
    "    ax.xaxis.label.set_color('white')\n",
    "    ax.yaxis.label.set_color('white')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    ax.set_title('PN Activity', color='white')\n",
    "    #ax.axvline(x=[time], color='white')\n",
    "\n",
    "    f = plt.subplot(7,1,3)\n",
    "    f.patch.set_facecolor('xkcd:black')\n",
    "    data = fo3.get_output(var='V')\n",
    "    PNs = [i for i in data.keys() if 'LN' in i]\n",
    "    sim_traces['V'] = {}\n",
    "    if len(PNs)>0.:\n",
    "        for PN in PNs[:]:\n",
    "            plt.plot(data[PN]['time'], data[PN]['data'])\n",
    "            sim_traces['V'][PN] = {'time': data[PN]['time'], 'data': data[PN]['data']}\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Membrane Potential')\n",
    "        ax = plt.gca()\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['top'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        ax.spines['right'].set_color('white')\n",
    "        ax.xaxis.label.set_color('white')\n",
    "        ax.yaxis.label.set_color('white')\n",
    "        ax.tick_params(axis='x', colors='white')\n",
    "        ax.tick_params(axis='y', colors='white')\n",
    "        ax.set_title('LN Activity', color='white')\n",
    "        #ax.axvline(x=[time], color='white')\n",
    "\n",
    "    f = plt.subplot(7,1,4)\n",
    "    f.patch.set_facecolor('xkcd:black')\n",
    "    data = fo.get_output(var='I')\n",
    "    PNs = [i for i in data.keys() if '_AT' in i and 'PN' in i and filter_keyword in i]\n",
    "    sim_traces['I'] = {}\n",
    "    for i in range(len(PNs)):\n",
    "        plt.plot(data[PNs[i]]['time'], data[PNs[i]]['data'])\n",
    "        sim_traces['I'][PNs[i]] = {'time': data[PNs[i]]['time'], 'data': data[PNs[i]]['data']}\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Current')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['top'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.spines['right'].set_color('white')\n",
    "    ax.xaxis.label.set_color('white')\n",
    "    ax.yaxis.label.set_color('white')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    ax.set_title('Individual ORN>PN Synapse Current', color='white')\n",
    "    #ax.axvline(x=[time], color='white')\n",
    "\n",
    "    f = plt.subplot(7,1,5)\n",
    "    f.patch.set_facecolor('xkcd:black')\n",
    "    data = fo.get_output(var='I')\n",
    "    PNs = [i for i in data.keys() if '_AT' in i and 'LN' in i and filter_keyword in i]\n",
    "    if len(PNs)>0.:\n",
    "        for i in range(len(PNs)):\n",
    "            plt.plot(data[PNs[i]]['time'], data[PNs[i]]['data'])\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Current')\n",
    "        ax = plt.gca()\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['top'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        ax.spines['right'].set_color('white')\n",
    "        ax.xaxis.label.set_color('white')\n",
    "        ax.yaxis.label.set_color('white')\n",
    "        ax.tick_params(axis='x', colors='white')\n",
    "        ax.tick_params(axis='y', colors='white')\n",
    "        ax.set_title('Individual ORN>LN Synapse Current', color='white')\n",
    "        #ax.axvline(x=[time], color='white')\n",
    "\n",
    "    f = plt.subplot(7,1,6)\n",
    "    f.patch.set_facecolor('xkcd:black')\n",
    "    data = fo.get_output(var='I')\n",
    "    PNs = [i for i in data.keys() if '_Converter' in i and 'LN' in i and PN_filter_keyword in i and 'PN' in i and not i.startswith(PN_filter_keyword)]\n",
    "    if len(PNs)>0.:\n",
    "        for i in range(len(PNs)):\n",
    "            plt.plot(data[PNs[i]]['time'], data[PNs[i]]['data'])\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Current')\n",
    "        ax = plt.gca()\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['top'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        ax.spines['right'].set_color('white')\n",
    "        ax.xaxis.label.set_color('white')\n",
    "        ax.yaxis.label.set_color('white')\n",
    "        ax.tick_params(axis='x', colors='white')\n",
    "        ax.tick_params(axis='y', colors='white')\n",
    "        ax.set_title('Individual LN>PN Synapse Current', color='white')\n",
    "        #ax.axvline(x=[time], color='white')\n",
    "\n",
    "    f = plt.subplot(7,1,7)\n",
    "    f.patch.set_facecolor('xkcd:black')\n",
    "    data = fo.get_output(var='I')\n",
    "    PNs = [i for i in data.keys() if '_Converter' in i and 'LN' in i and PN_filter_keyword in i and 'PN' in i and i.startswith(PN_filter_keyword)]\n",
    "    if len(PNs)>0.:\n",
    "        for i in range(len(PNs)):\n",
    "            plt.plot(data[PNs[i]]['time'], data[PNs[i]]['data'])\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Current')\n",
    "        ax = plt.gca()\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['top'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        ax.spines['right'].set_color('white')\n",
    "        ax.xaxis.label.set_color('white')\n",
    "        ax.yaxis.label.set_color('white')\n",
    "        ax.tick_params(axis='x', colors='white')\n",
    "        ax.tick_params(axis='y', colors='white')\n",
    "        ax.set_title('Individual PN>LN Synapse Current', color='white')\n",
    "        #ax.axvline(x=[time], color='white')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}_conc.png'.format(sim_name))\n",
    "    plt.close()\n",
    "    \n",
    "    data = fo2.get_output(var='spike_state')\n",
    "    PNs = [i for i in data.keys() if 'PN' in i and PN_filter_keyword in i]\n",
    "    sim_traces['psth'] = {}\n",
    "    sim_traces['spike_state'] = {}\n",
    "    for PN in PNs[:]:\n",
    "        \n",
    "        spike_times = time_axis\n",
    "        spike_data = spike_times * 0.\n",
    "        real_spike_data = data[PN]['data']\n",
    "        if data[PN]['data'].shape[0]>0:\n",
    "            for i in range(time_axis.shape[0]):\n",
    "                if np.min(np.abs(time_axis[i] - data[PN]['data']))<dt/2:\n",
    "                    spike_data[i] = 1.\n",
    "        psth_data = PSTH( spike_data, 1e-5, window=3e-1, shift=50e-3)\n",
    "        psth_step = psth_data.psth\n",
    "        psth_t = psth_data.t\n",
    "        sim_traces['psth'][PN] = {'time': psth_t, 'data': psth_step}\n",
    "        # plt.plot(psth_t, psth_step)\n",
    "        sim_traces['spike_state'][PN] = {'time': real_spike_data}\n",
    "    return sim_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-interstate",
   "metadata": {},
   "source": [
    "# Single Glomerulus Simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "names = ['DL5_3_all']\n",
    "simulation_traces = {}\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0]:\n",
    "        for DL5_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DL5_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=True, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)\n",
    "            \n",
    "names = ['DL5_3_ln1', 'DL5_3_ln12', 'DL5_3_ln2', 'DL5_3_lnless']\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0]:\n",
    "        for DL5_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DL5_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=False, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "names = ['DL5_3i_all']\n",
    "simulation_traces = {}\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0]:\n",
    "        for DL5_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DL5_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=True, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)\n",
    "            \n",
    "names = ['DL5_3i_ln1', 'DL5_3i_ln12', 'DL5_3i_ln2', 'DL5_3i_lnless']\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0]:\n",
    "        for DL5_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DL5_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=False, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "names = ['DM4_3_all']\n",
    "simulation_traces = {}\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for DL5_b_coeff in [0.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DM4_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=True, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "names = ['DM4_3i_all']\n",
    "simulation_traces = {}\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for DL5_b_coeff in [0.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DM4_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=True, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)\n",
    "            \n",
    "names = ['DM4_3_ln1', 'DM4_3_ln12', 'DM4_3_ln2', 'DM4_3_lnless']\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for DL5_b_coeff in [0.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DM4_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=False, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "names = ['DM4_3i_all']\n",
    "simulation_traces = {}\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for DL5_b_coeff in [0.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DM4_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=True, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)\n",
    "            \n",
    "names = ['DM4_3i_ln1', 'DM4_3i_ln12', 'DM4_3i_ln2', 'DM4_3i_lnless']\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for DL5_b_coeff in [0.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = main_path + '{}.gexf'.format(name)\n",
    "            visual_components = np.load(main_path + 'visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load(main_path + 'visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, \n",
    "                                              exp_name = '_my_DM4_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff), LN_3=False, LN_3_I = 20.)\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "names = ['DM4DL5_3_full']\n",
    "simulation_traces = {}\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0,0.2,0.4,0.6,0.8,1.0]:\n",
    "        for DL5_b_coeff in [0.0,0.2,0.4,0.6,0.8,1.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = '/mnt/server-home/mehmet/alclustering/{}.gexf'.format(name)\n",
    "            visual_components = np.load('/mnt/server-home/mehmet/alclustering/visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load('/mnt/server-home/mehmet/alclustering/visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, exp_name = '_my_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff))\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)\n",
    "            \n",
    "import time\n",
    "import gc\n",
    "names = ['DM4DL5_3_ln1', 'DM4DL5_3_ln2', 'DM4DL5_3_ln12']\n",
    "simulation_traces = {}\n",
    "for name in names:\n",
    "    for DM4_b_coeff in [0.0,0.2,0.4,0.6,0.8,1.0]:\n",
    "        for DL5_b_coeff in [0.0,0.2,0.4,0.6,0.8,1.0]:\n",
    "            time.sleep(1)\n",
    "            conc = 10.\n",
    "            G_path = '/mnt/server-home/mehmet/alclustering/{}.gexf'.format(name)\n",
    "            visual_components = np.load('/mnt/server-home/mehmet/alclustering/visual_components_{}.npy'.format(name), allow_pickle=True)\n",
    "            visual_neurons = np.load('/mnt/server-home/mehmet/alclustering/visual_neurons_{}.npy'.format(name), allow_pickle=True).item()\n",
    "            simulate, G, fi = large_scale_sim(name, G_path, conc=conc, DM4_b = DM4_b_coeff * 0.3, DM4_d = 2.94, DL5_b = DL5_b_coeff * 0.3, exp_name = '_my_experiment_' + str(DM4_b_coeff) + '_' + str(DL5_b_coeff))\n",
    "            dt = 1e-5\n",
    "            dur = 4.\n",
    "            steps = int((dur+dt/2)//dt)\n",
    "            t = np.arange(steps)*dt\n",
    "            fi, fo, fo2, fo3, lpu = simulate(G, t, fi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
